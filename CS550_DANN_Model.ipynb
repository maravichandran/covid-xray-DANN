{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIsLZYNlefYH"
   },
   "source": [
    "This notebook contains our DANN model implementation and results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ug47eegr1oj"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t93EHtfiXaiV"
   },
   "source": [
    "The code for importing the data is largely the same as the following notebook: https://www.kaggle.com/arunlukedsouza/covid-19-chest-x-ray-classification-with-resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o34tTvUHl8S9"
   },
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "mBy5_FiYmuHb",
    "outputId": "9ce7f223-de89-4c44-e3ba-a75603a8487a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-135f00b0-3310-4099-94b5-ec5a49e5771b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-135f00b0-3310-4099-94b5-ec5a49e5771b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle (1).json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"michaelmcgillicuddy\",\"key\":\"c3e5cf2c2ff68b0ac65ee04b4e576efe\"}'}"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "We_BvBGsm9va",
    "outputId": "1fd02b19-d83a-4baf-f313-12283f8e086d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5p2HNLOxn1pT",
    "outputId": "b15aa10f-ef29-4910-88c8-2b2571d882bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid19-radiography-database.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d tawsifurrahman/covid19-radiography-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqmeoX7np7ST",
    "outputId": "57b36f6c-68ec-4e9b-87bf-71bf9fa15df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  covid19-radiography-database.zip\n",
      "replace COVID-19_Radiography_Dataset/COVID.metadata.xlsx? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "! unzip covid19-radiography-database.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snbHS-uIOZ78",
    "outputId": "3944da25-8534-4303-e2f3-070479784204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chest-xray-pneumonia.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1H8LvTN6OZc0",
    "outputId": "b35618a9-fcab-41fb-c0ca-c32f7ffcdd35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  chest-xray-pneumonia.zip\n",
      "replace chest_xray/__MACOSX/._chest_xray? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "! unzip chest-xray-pneumonia.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBcvxF3qYbfN",
    "outputId": "ff0bd9ad-1948-400b-ff70-30806ca113c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0244cd1450>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from distutils.dir_util import copy_tree\n",
    "from torch.autograd import Variable\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Define constants\n",
    "max_epochs = 5\n",
    "batch_size = 3\n",
    "src_acc = []\n",
    "tgt_acc = []\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20VzzntbWmdd"
   },
   "source": [
    "# Setup of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IM_nij4zXpYz"
   },
   "source": [
    "This section creates the file structures necessary to process the data and loads it into the appropriate DataLoader objects for analysis with PyTorch. We also do data augmentation in this section. The code for setting up the data is adapted from https://www.kaggle.com/arunlukedsouza/covid-19-chest-x-ray-classification-with-resnet-18. Some of the changes we made were bringing in an extra dataset from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia to bring in more pneumonia and normal images to our dataset and adapting the code to use healthy and unhealthy classes instead of pneumonia & no-pneumonia.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcFd2qYMq5Tm"
   },
   "outputs": [],
   "source": [
    "# Define file locations\n",
    "directory ='/content/COVID-19_Radiography_Dataset'\n",
    "\n",
    "source_dirs = ['Normal', 'Viral Pneumonia', 'COVID']\n",
    "input_dir = '/content/train'\n",
    "output_dir = '/content/test'\n",
    "\n",
    "normal_dir = '/content/COVID-19_Radiography_Dataset/Normal'\n",
    "pneumonia_dir_1 = '/content/COVID-19_Radiography_Dataset/Viral Pneumonia'\n",
    "covid_dir = '/content/COVID-19_Radiography_Dataset/COVID'\n",
    "\n",
    "pneumonia_dir_2 = '/content/chest_xray/train/PNEUMONIA'\n",
    "    \n",
    "if os.path.isdir(os.path.join(directory, source_dirs[1])):\n",
    "    if os.path.exists(input_dir):\n",
    "      shutil.rmtree(input_dir)\n",
    "    \n",
    "    # Create Train Dir\n",
    "    os.makedirs(input_dir)            \n",
    "    os.makedirs(input_dir + '/Normal')\n",
    "    os.makedirs(input_dir + '/Viral Pneumonia')\n",
    "    os.makedirs(input_dir + '/COVID')\n",
    "        \n",
    "    # Copy Classes to Train\n",
    "    copy_tree(normal_dir, input_dir + '/Normal')\n",
    "    copy_tree(pneumonia_dir_1, input_dir + '/Viral Pneumonia')\n",
    "    copy_tree(pneumonia_dir_2, input_dir + '/Viral Pneumonia')\n",
    "\n",
    "    copy_tree(covid_dir, input_dir + '/COVID')\n",
    "        \n",
    "    if os.path.exists(output_dir):\n",
    "      shutil.rmtree(output_dir)      \n",
    "          \n",
    "    # Create Test Dir\n",
    "    os.makedirs(output_dir)            \n",
    "    os.makedirs(output_dir + '/Normal')\n",
    "    os.makedirs(output_dir + '/Viral Pneumonia')\n",
    "    os.makedirs(output_dir + '/COVID')\n",
    "\n",
    "    # Create Test Dir Classes\n",
    "    for c in source_dirs:\n",
    "        if not os.path.isdir(os.path.join(output_dir, c)):\n",
    "            os.mkdir(os.path.join(output_dir, c))\n",
    "\n",
    "    # Choose 1000 images per type to be moved to test  \n",
    "    for c in source_dirs:\n",
    "        images = [x for x in os.listdir(os.path.join(input_dir, c))]# if x.lower().endswith('png')]\n",
    "        selected_images = random.sample(images, 1000)\n",
    "        for image in selected_images:\n",
    "            source_path = os.path.join(input_dir, c, image)\n",
    "            target_path = os.path.join(output_dir, c, image)\n",
    "            shutil.move(source_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1glZkWeVyvn3"
   },
   "outputs": [],
   "source": [
    "#code for initializing and transforming the datasets\n",
    "class ChestXRayDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, image_dirs, transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name])]# if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)} {class_name} examples')\n",
    "            return images\n",
    "        \n",
    "        self.images = {}\n",
    "        self.class_names = ['Healthy', 'Unhealthy']\n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            self.images[class_name] = get_images(class_name)\n",
    "            \n",
    "        self.image_dirs = image_dirs\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[class_name]) for class_name in self.class_names])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        class_name = random.choice(self.class_names)\n",
    "        index = index % len(self.images[class_name])\n",
    "        image_name = self.images[class_name][index]\n",
    "        image_path = os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return self.transform(image), self.class_names.index(class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DF4dykwAMewt"
   },
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=(175,175)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(), #A RandomHorizontalFlip to augment our data\n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                    std = [0.229, 0.224, 0.225]) #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRV2t9MjMjzv"
   },
   "outputs": [],
   "source": [
    "test_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=(175,175)),\n",
    "    # We don't do data augmentation in the test/val set    \n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                    std = [0.229, 0.224, 0.225]) #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTuwM6UINIgN",
    "outputId": "f2f94e1f-6077-4a1c-e1e8-2de027f77f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9192 Healthy examples\n",
      "Found 4220 Unhealthy examples\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Healthy': input_dir + '/Normal',\n",
    "    'Unhealthy': input_dir + '/Viral Pneumonia'\n",
    "}\n",
    "\n",
    "train_dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRZ2fNp7NzRl",
    "outputId": "db4b1cf8-d8e4-40c9-a69c-154cfa1a6cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 Healthy examples\n",
      "Found 1000 Unhealthy examples\n"
     ]
    }
   ],
   "source": [
    "test_dirs = {\n",
    "    'Healthy': output_dir + '/Normal',\n",
    "    'Unhealthy': output_dir + '/Viral Pneumonia'\n",
    "}\n",
    "\n",
    "test_dataset = ChestXRayDataset(test_dirs, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mwJjplmTPYi",
    "outputId": "543bc851-6cb6-4183-fc3f-97efdd897d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9192 Healthy examples\n",
      "Found 2616 Unhealthy examples\n"
     ]
    }
   ],
   "source": [
    "DA_train_dirs = {\n",
    "    'Healthy': input_dir + '/Normal',\n",
    "    'Unhealthy': input_dir + '/COVID' \n",
    "}\n",
    "\n",
    "DA_train_dataset = ChestXRayDataset(DA_train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOrrVuNPUT3K",
    "outputId": "ad61c567-e40e-46b1-9246-d26153e100c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 Healthy examples\n",
      "Found 1000 Unhealthy examples\n"
     ]
    }
   ],
   "source": [
    "DA_test_dirs = {\n",
    "    'Healthy': output_dir + '/Normal',\n",
    "    'Unhealthy': output_dir + '/COVID' \n",
    "}\n",
    "\n",
    "DA_test_dataset = ChestXRayDataset(DA_test_dirs, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOYrqV0vOBZB",
    "outputId": "12bad7f0-dc04-4cd1-a4a1-90d94b61a950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of source train batches 4471\n",
      "Num of source test batches 667\n",
      "Num of target train batches 3936\n",
      "Num of target test batches 667\n"
     ]
    }
   ],
   "source": [
    "dl_source_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_source_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_target_train = torch.utils.data.DataLoader(DA_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_target_test = torch.utils.data.DataLoader(DA_test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print('Num of source train batches', len(dl_source_train))\n",
    "print('Num of source test batches', len(dl_source_test))\n",
    "print('Num of target train batches', len(dl_target_train))\n",
    "print('Num of target test batches', len(dl_target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbh7I-MaWynT"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C57HcE1JaMqT"
   },
   "source": [
    "This section defines the neural network architecture for the model and uses a DANN implementation with a gradient reversal layer for domain adaptation. The code is adapted from https://github.com/CuthbertCai/pytorch_DANN/, with our changes involving making it work with our dataset in general and more specifically resizing the neural network layers so they work with our dataset. The CuthbertCai repository used the MNIST and SVHN datasets (images of numbers) for their model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K82DvivM8eyz"
   },
   "outputs": [],
   "source": [
    "#From https://github.com/CuthbertCai/pytorch_DANN/blob/540e0c1699eece8496274342e561524429de9210/models/models.py#L7\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Extension of grad reverse layer\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, constant):\n",
    "        ctx.constant = constant\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_output = grad_output.neg() * ctx.constant\n",
    "        return grad_output, None\n",
    "\n",
    "    def grad_reverse(x, constant):\n",
    "        return GradReverse.apply(x, constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR-KBMmIhenv"
   },
   "outputs": [],
   "source": [
    "#Adapted from: https://github.com/CuthbertCai/pytorch_DANN/blob/master/models/models.py\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SVHN_Extractor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVHN_Extractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size= 5)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size= 5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size= 5, padding= 2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode= 'fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.expand(input.data.shape[0], 3, 175, 175)\n",
    "        x = F.relu(self.bn1(self.conv1(input)))\n",
    "        x = F.max_pool2d(x, 3, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 3, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv3_drop(x)\n",
    "        \n",
    "        return x.view(-1, 128 * 40 * 40)\n",
    "\n",
    "class SVHN_Class_classifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVHN_Class_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128 * 40 * 40, 3200)\n",
    "        self.bn1 = nn.BatchNorm1d(3200)\n",
    "        self.fc2 = nn.Linear(3200, 2048)\n",
    "        self.bn2 = nn.BatchNorm1d(2048)\n",
    "        self.fc3 = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        logits = F.relu(self.bn1(self.fc1(input)))\n",
    "        logits = F.dropout(logits)\n",
    "        logits = F.relu(self.bn2(self.fc2(logits)))\n",
    "        logits = self.fc3(logits)\n",
    "\n",
    "        return F.log_softmax(logits, 1)\n",
    "\n",
    "class SVHN_Domain_classifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVHN_Domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128 * 40 * 40, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.fc3 = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, input, constant):\n",
    "        input = GradReverse.grad_reverse(input, constant)\n",
    "        logits = F.relu(self.bn1(self.fc1(input)))\n",
    "        logits = F.dropout(logits)\n",
    "        logits = F.relu(self.bn2(self.fc2(logits)))\n",
    "        logits = F.dropout(logits)\n",
    "        logits = self.fc3(logits)\n",
    "\n",
    "        return F.log_softmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D77r09Yj1f2b"
   },
   "outputs": [],
   "source": [
    "# Code from https://github.com/CuthbertCai/pytorch_DANN/blob/master/util/utils.py\n",
    "def optimizer_scheduler(optimizer, p):\n",
    "    \"\"\"\n",
    "    Adjust the learning rate of optimizer\n",
    "    :param optimizer: optimizer for updating parameters\n",
    "    :param p: a variable for adjusting learning rate\n",
    "    :return: optimizer\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H4m7RrSW5k7"
   },
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF4yXTM5d6e9"
   },
   "source": [
    "This is the code we used to train and test our model, also adapted from https://github.com/CuthbertCai/pytorch_DANN/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldaN-tGePx9c"
   },
   "outputs": [],
   "source": [
    "# Code adapted from https://github.com/CuthbertCai/pytorch_DANN/blob/master/train/train.py\n",
    "def train(training_mode, feature_extractor, class_classifier, domain_classifier, class_criterion, domain_criterion,\n",
    "          source_dataloader, target_dataloader, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Execute target domain adaptation\n",
    "    :param training_mode:\n",
    "    :param feature_extractor:\n",
    "    :param class_classifier:\n",
    "    :param domain_classifier:\n",
    "    :param class_criterion:\n",
    "    :param domain_criterion:\n",
    "    :param source_dataloader:\n",
    "    :param target_dataloader:\n",
    "    :param optimizer:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # setup models\n",
    "    feature_extractor.train()\n",
    "    class_classifier.train()\n",
    "    domain_classifier.train()\n",
    "\n",
    "    # steps\n",
    "    start_steps = epoch * len(source_dataloader)\n",
    "    total_steps = max_epochs * len(source_dataloader)\n",
    "\n",
    "    for batch_idx, (sdata, tdata) in enumerate(zip(source_dataloader, target_dataloader)):\n",
    "\n",
    "        if training_mode == 'dann':\n",
    "            # setup hyperparameters\n",
    "            p = float(batch_idx + start_steps) / total_steps\n",
    "            constant = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "            # prepare the data\n",
    "            input1, label1 = sdata\n",
    "            input2, label2 = tdata\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "            for i in [input1, label1, input2, label2]: #send data to GPU\n",
    "                i = i.to(device)\n",
    "            size = min((input1.shape[0], input2.shape[0]))\n",
    "            input1, label1 = input1[0:size, :, :, :], label1[0:size]\n",
    "            input2, label2 = input2[0:size, :, :, :], label2[0:size]\n",
    "\n",
    "            input1, label1 = Variable(input1.cuda()), Variable(label1.cuda())\n",
    "            input2, label2 = Variable(input2.cuda()), Variable(label2.cuda())\n",
    "\n",
    "            # setup optimizer\n",
    "            optimizer = optimizer_scheduler(optimizer, p)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # prepare domain labels\n",
    "            source_labels = Variable(torch.zeros((input1.size()[0])).type(torch.LongTensor).cuda())\n",
    "            target_labels = Variable(torch.ones((input2.size()[0])).type(torch.LongTensor).cuda())\n",
    "\n",
    "            # compute the output of source domain and target domain\n",
    "            src_feature = feature_extractor(input1)\n",
    "            tgt_feature = feature_extractor(input2)\n",
    "\n",
    "            # compute the class loss of src_feature\n",
    "            class_preds = class_classifier(src_feature)\n",
    "            class_loss = class_criterion(class_preds, label1)\n",
    "\n",
    "            # compute the domain loss of src_feature and target_feature\n",
    "            tgt_preds = domain_classifier(tgt_feature, constant)\n",
    "            src_preds = domain_classifier(src_feature, constant)\n",
    "            tgt_loss = domain_criterion(tgt_preds, target_labels)\n",
    "            src_loss = domain_criterion(src_preds, source_labels)\n",
    "            domain_loss = tgt_loss + src_loss\n",
    "\n",
    "            loss = class_loss + 1 * domain_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print loss\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print('[{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tClass Loss: {:.6f}\\tDomain Loss: {:.6f}'.format(\n",
    "                    batch_idx * len(input2), len(target_dataloader.dataset),\n",
    "                    100. * batch_idx / len(target_dataloader), loss.item(), class_loss.item(),\n",
    "                    domain_loss.item()\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNpHu2evhVQo"
   },
   "outputs": [],
   "source": [
    "# From https://github.com/CuthbertCai/pytorch_DANN/blob/master/train/test.py\n",
    "\n",
    "\"\"\"\n",
    "Test the model with target domain\n",
    "\"\"\"\n",
    "\n",
    "def test(feature_extractor, class_classifier, domain_classifier, source_dataloader, target_dataloader):\n",
    "    \"\"\"\n",
    "    Test the performance of the model\n",
    "    :param feature_extractor: network used to extract feature from target samples\n",
    "    :param class_classifier: network used to predict labels\n",
    "    :param domain_classifier: network used to predict domain\n",
    "    :param source_dataloader: test dataloader of source domain\n",
    "    :param target_dataloader: test dataloader of target domain\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # setup the network\n",
    "    feature_extractor.eval()\n",
    "    class_classifier.eval()\n",
    "    domain_classifier.eval()\n",
    "    source_correct = 0.0\n",
    "    target_correct = 0.0\n",
    "    domain_correct = 0.0\n",
    "    tgt_correct = 0.0\n",
    "    src_correct = 0.0\n",
    "\n",
    "    for batch_idx, sdata in enumerate(source_dataloader):\n",
    "        # setup hyperparameters\n",
    "        p = float(batch_idx) / len(source_dataloader)\n",
    "        constant = 2. / (1. + np.exp(-10 * p)) - 1.\n",
    "\n",
    "        input1, label1 = sdata\n",
    "\n",
    "        input1, label1 = Variable(input1.cuda()), Variable(label1.cuda())\n",
    "        src_labels = Variable(torch.zeros((input1.size()[0])).type(torch.LongTensor).cuda())\n",
    "      \n",
    "        output1 = class_classifier(feature_extractor(input1))\n",
    "        pred1 = output1.data.max(1, keepdim = True)[1]\n",
    "        source_correct += pred1.eq(label1.data.view_as(pred1)).cpu().sum()\n",
    "\n",
    "        src_preds = domain_classifier(feature_extractor(input1), constant)\n",
    "        src_preds = src_preds.data.max(1, keepdim= True)[1]\n",
    "        src_correct += src_preds.eq(src_labels.data.view_as(src_preds)).cpu().sum()\n",
    "\n",
    "    for batch_idx, tdata in enumerate(target_dataloader):\n",
    "        # setup hyperparameters\n",
    "        p = float(batch_idx) / len(source_dataloader)\n",
    "        constant = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        input2, label2 = tdata\n",
    "        \n",
    "        input2, label2 = Variable(input2.cuda()), Variable(label2.cuda())\n",
    "        tgt_labels = Variable(torch.ones((input2.size()[0])).type(torch.LongTensor).cuda())\n",
    "\n",
    "        output2 = class_classifier(feature_extractor(input2))\n",
    "        pred2 = output2.data.max(1, keepdim=True)[1]\n",
    "        target_correct += pred2.eq(label2.data.view_as(pred2)).cpu().sum()\n",
    "\n",
    "        tgt_preds = domain_classifier(feature_extractor(input2), constant)\n",
    "        tgt_preds = tgt_preds.data.max(1, keepdim=True)[1]\n",
    "        tgt_correct += tgt_preds.eq(tgt_labels.data.view_as(tgt_preds)).cpu().sum()\n",
    "\n",
    "    domain_correct = tgt_correct + src_correct\n",
    "\n",
    "    src_acc.append(100. * float(source_correct) / len(source_dataloader.dataset))\n",
    "    tgt_acc.append(100. * float(target_correct) / len(target_dataloader.dataset))\n",
    "\n",
    "    print('\\nSource Accuracy: {}/{} ({:.4f}%)\\nTarget Accuracy: {}/{} ({:.4f}%)\\n'.\n",
    "        format(\n",
    "        source_correct, len(source_dataloader.dataset), 100. * float(source_correct) / len(source_dataloader.dataset),\n",
    "        target_correct, len(target_dataloader.dataset), 100. * float(target_correct) / len(target_dataloader.dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zn81vA-sXAh5"
   },
   "source": [
    "# Execution and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7dcsuXnbEka"
   },
   "source": [
    "It takes around 60-90 minutes to run the model each time. The accuracy results varied slightly each time we trained and ran the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njsWT8EkXZmJ",
    "outputId": "86bf8aed-cce0-4d52-8129-5b257e52e6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[147/11808 (1%)]\tLoss: 15.218534\tClass Loss: 0.002978\tDomain Loss: 15.215555\n",
      "[297/11808 (3%)]\tLoss: 22.098192\tClass Loss: 0.000000\tDomain Loss: 22.098192\n",
      "[447/11808 (4%)]\tLoss: 28.462948\tClass Loss: 7.508236\tDomain Loss: 20.954712\n",
      "[597/11808 (5%)]\tLoss: 21.325884\tClass Loss: 0.010696\tDomain Loss: 21.315187\n",
      "[747/11808 (6%)]\tLoss: 9.139538\tClass Loss: 0.000047\tDomain Loss: 9.139491\n",
      "[897/11808 (8%)]\tLoss: 8.356174\tClass Loss: 0.000000\tDomain Loss: 8.356174\n",
      "[1047/11808 (9%)]\tLoss: 2.327026\tClass Loss: 0.613053\tDomain Loss: 1.713973\n",
      "[1197/11808 (10%)]\tLoss: 9.957016\tClass Loss: 4.197675\tDomain Loss: 5.759341\n",
      "[1347/11808 (11%)]\tLoss: 1.828656\tClass Loss: 0.000000\tDomain Loss: 1.828656\n",
      "[1497/11808 (13%)]\tLoss: 4.783556\tClass Loss: 1.619757\tDomain Loss: 3.163800\n",
      "[1647/11808 (14%)]\tLoss: 3.038420\tClass Loss: 0.259482\tDomain Loss: 2.778938\n",
      "[1797/11808 (15%)]\tLoss: 3.697601\tClass Loss: 0.821261\tDomain Loss: 2.876340\n",
      "[1947/11808 (16%)]\tLoss: 20.829535\tClass Loss: 17.270559\tDomain Loss: 3.558975\n",
      "[2097/11808 (18%)]\tLoss: 2.269045\tClass Loss: 0.688991\tDomain Loss: 1.580054\n",
      "[2247/11808 (19%)]\tLoss: 1.453598\tClass Loss: 0.000785\tDomain Loss: 1.452813\n",
      "[2397/11808 (20%)]\tLoss: 5.889082\tClass Loss: 4.282066\tDomain Loss: 1.607017\n",
      "[2547/11808 (22%)]\tLoss: 1.958064\tClass Loss: 0.003973\tDomain Loss: 1.954091\n",
      "[2697/11808 (23%)]\tLoss: 9.958482\tClass Loss: 8.071475\tDomain Loss: 1.887007\n",
      "[2847/11808 (24%)]\tLoss: 1.842143\tClass Loss: 0.003014\tDomain Loss: 1.839128\n",
      "[2997/11808 (25%)]\tLoss: 4.164420\tClass Loss: 2.291136\tDomain Loss: 1.873284\n",
      "[3147/11808 (27%)]\tLoss: 1.424975\tClass Loss: 0.027677\tDomain Loss: 1.397298\n",
      "[3297/11808 (28%)]\tLoss: 3.929670\tClass Loss: 2.350623\tDomain Loss: 1.579047\n",
      "[3447/11808 (29%)]\tLoss: 1.257544\tClass Loss: 0.187029\tDomain Loss: 1.070515\n",
      "[3597/11808 (30%)]\tLoss: 2.275071\tClass Loss: 0.907443\tDomain Loss: 1.367628\n",
      "[3747/11808 (32%)]\tLoss: 1.427518\tClass Loss: 0.001283\tDomain Loss: 1.426235\n",
      "[3897/11808 (33%)]\tLoss: 1.517197\tClass Loss: 0.019662\tDomain Loss: 1.497535\n",
      "[4047/11808 (34%)]\tLoss: 3.079691\tClass Loss: 1.586366\tDomain Loss: 1.493326\n",
      "[4197/11808 (36%)]\tLoss: 2.611602\tClass Loss: 1.049577\tDomain Loss: 1.562025\n",
      "[4347/11808 (37%)]\tLoss: 6.603300\tClass Loss: 4.980509\tDomain Loss: 1.622790\n",
      "[4497/11808 (38%)]\tLoss: 1.318662\tClass Loss: 0.004359\tDomain Loss: 1.314302\n",
      "[4647/11808 (39%)]\tLoss: 8.595060\tClass Loss: 6.597158\tDomain Loss: 1.997902\n",
      "[4797/11808 (41%)]\tLoss: 1.875911\tClass Loss: 0.046211\tDomain Loss: 1.829700\n",
      "[4947/11808 (42%)]\tLoss: 3.632766\tClass Loss: 2.129288\tDomain Loss: 1.503478\n",
      "[5097/11808 (43%)]\tLoss: 1.295652\tClass Loss: 0.006878\tDomain Loss: 1.288774\n",
      "[5247/11808 (44%)]\tLoss: 8.080465\tClass Loss: 6.497551\tDomain Loss: 1.582915\n",
      "[5397/11808 (46%)]\tLoss: 1.459943\tClass Loss: 0.046928\tDomain Loss: 1.413015\n",
      "[5547/11808 (47%)]\tLoss: 1.471250\tClass Loss: 0.013910\tDomain Loss: 1.457340\n",
      "[5697/11808 (48%)]\tLoss: 1.940005\tClass Loss: 0.265153\tDomain Loss: 1.674851\n",
      "[5847/11808 (50%)]\tLoss: 1.483211\tClass Loss: 0.001821\tDomain Loss: 1.481390\n",
      "[5997/11808 (51%)]\tLoss: 2.005339\tClass Loss: 0.396542\tDomain Loss: 1.608797\n",
      "[6147/11808 (52%)]\tLoss: 1.408467\tClass Loss: 0.097830\tDomain Loss: 1.310636\n",
      "[6297/11808 (53%)]\tLoss: 5.591804\tClass Loss: 4.021602\tDomain Loss: 1.570201\n",
      "[6447/11808 (55%)]\tLoss: 8.722944\tClass Loss: 7.127798\tDomain Loss: 1.595147\n",
      "[6597/11808 (56%)]\tLoss: 1.321803\tClass Loss: 0.006607\tDomain Loss: 1.315196\n",
      "[6747/11808 (57%)]\tLoss: 1.476383\tClass Loss: 0.000583\tDomain Loss: 1.475801\n",
      "[6897/11808 (58%)]\tLoss: 1.496469\tClass Loss: 0.160984\tDomain Loss: 1.335485\n",
      "[7047/11808 (60%)]\tLoss: 2.985881\tClass Loss: 1.469542\tDomain Loss: 1.516339\n",
      "[7197/11808 (61%)]\tLoss: 1.097264\tClass Loss: 0.013306\tDomain Loss: 1.083958\n",
      "[7347/11808 (62%)]\tLoss: 1.551035\tClass Loss: 0.024831\tDomain Loss: 1.526204\n",
      "[7497/11808 (63%)]\tLoss: 2.442418\tClass Loss: 0.767381\tDomain Loss: 1.675037\n",
      "[7647/11808 (65%)]\tLoss: 1.626820\tClass Loss: 0.011382\tDomain Loss: 1.615438\n",
      "[7797/11808 (66%)]\tLoss: 2.545242\tClass Loss: 1.014862\tDomain Loss: 1.530380\n",
      "[7947/11808 (67%)]\tLoss: 1.762479\tClass Loss: 0.472487\tDomain Loss: 1.289991\n",
      "[8097/11808 (69%)]\tLoss: 3.000390\tClass Loss: 1.689031\tDomain Loss: 1.311359\n",
      "[8247/11808 (70%)]\tLoss: 1.503277\tClass Loss: 0.193895\tDomain Loss: 1.309382\n",
      "[8397/11808 (71%)]\tLoss: 1.498209\tClass Loss: 0.052700\tDomain Loss: 1.445508\n",
      "[8547/11808 (72%)]\tLoss: 1.770595\tClass Loss: 0.477937\tDomain Loss: 1.292658\n",
      "[8697/11808 (74%)]\tLoss: 1.528669\tClass Loss: 0.191592\tDomain Loss: 1.337077\n",
      "[8847/11808 (75%)]\tLoss: 1.306407\tClass Loss: 0.010462\tDomain Loss: 1.295945\n",
      "[8997/11808 (76%)]\tLoss: 1.413431\tClass Loss: 0.153158\tDomain Loss: 1.260273\n",
      "[9147/11808 (77%)]\tLoss: 2.014107\tClass Loss: 0.453987\tDomain Loss: 1.560120\n",
      "[9297/11808 (79%)]\tLoss: 1.632450\tClass Loss: 0.189790\tDomain Loss: 1.442659\n",
      "[9447/11808 (80%)]\tLoss: 1.500866\tClass Loss: 0.115721\tDomain Loss: 1.385145\n",
      "[9597/11808 (81%)]\tLoss: 1.435071\tClass Loss: 0.042313\tDomain Loss: 1.392759\n",
      "[9747/11808 (83%)]\tLoss: 1.307145\tClass Loss: 0.049170\tDomain Loss: 1.257975\n",
      "[9897/11808 (84%)]\tLoss: 3.373763\tClass Loss: 1.842941\tDomain Loss: 1.530822\n",
      "[10047/11808 (85%)]\tLoss: 3.402598\tClass Loss: 1.962858\tDomain Loss: 1.439740\n",
      "[10197/11808 (86%)]\tLoss: 1.309790\tClass Loss: 0.005178\tDomain Loss: 1.304612\n",
      "[10347/11808 (88%)]\tLoss: 1.400991\tClass Loss: 0.017925\tDomain Loss: 1.383067\n",
      "[10497/11808 (89%)]\tLoss: 1.395413\tClass Loss: 0.007652\tDomain Loss: 1.387761\n",
      "[10647/11808 (90%)]\tLoss: 1.379529\tClass Loss: 0.039561\tDomain Loss: 1.339968\n",
      "[10797/11808 (91%)]\tLoss: 2.688599\tClass Loss: 1.204654\tDomain Loss: 1.483945\n",
      "[10947/11808 (93%)]\tLoss: 1.621601\tClass Loss: 0.192469\tDomain Loss: 1.429132\n",
      "[11097/11808 (94%)]\tLoss: 1.917992\tClass Loss: 0.548488\tDomain Loss: 1.369503\n",
      "[11247/11808 (95%)]\tLoss: 1.880175\tClass Loss: 0.236514\tDomain Loss: 1.643660\n",
      "[11397/11808 (97%)]\tLoss: 1.520881\tClass Loss: 0.149061\tDomain Loss: 1.371820\n",
      "[11547/11808 (98%)]\tLoss: 2.740940\tClass Loss: 1.539205\tDomain Loss: 1.201735\n",
      "[11697/11808 (99%)]\tLoss: 2.325023\tClass Loss: 0.885397\tDomain Loss: 1.439626\n",
      "\n",
      "Source Accuracy: 1489.0/2000 (74.4500%)\n",
      "Target Accuracy: 1245.0/2000 (62.2500%)\n",
      "\n",
      "Epoch: 2\n",
      "[147/11808 (1%)]\tLoss: 1.742601\tClass Loss: 0.190520\tDomain Loss: 1.552081\n",
      "[297/11808 (3%)]\tLoss: 1.585670\tClass Loss: 0.161936\tDomain Loss: 1.423734\n",
      "[447/11808 (4%)]\tLoss: 1.444928\tClass Loss: 0.136105\tDomain Loss: 1.308823\n",
      "[597/11808 (5%)]\tLoss: 3.187069\tClass Loss: 1.848087\tDomain Loss: 1.338983\n",
      "[747/11808 (6%)]\tLoss: 2.195996\tClass Loss: 0.853144\tDomain Loss: 1.342852\n",
      "[897/11808 (8%)]\tLoss: 2.329775\tClass Loss: 0.861556\tDomain Loss: 1.468219\n",
      "[1047/11808 (9%)]\tLoss: 1.579607\tClass Loss: 0.336631\tDomain Loss: 1.242976\n",
      "[1197/11808 (10%)]\tLoss: 1.275854\tClass Loss: 0.012716\tDomain Loss: 1.263138\n",
      "[1347/11808 (11%)]\tLoss: 2.223211\tClass Loss: 0.811334\tDomain Loss: 1.411877\n",
      "[1497/11808 (13%)]\tLoss: 1.506992\tClass Loss: 0.096591\tDomain Loss: 1.410402\n",
      "[1647/11808 (14%)]\tLoss: 1.800002\tClass Loss: 0.393734\tDomain Loss: 1.406267\n",
      "[1797/11808 (15%)]\tLoss: 2.454576\tClass Loss: 1.048094\tDomain Loss: 1.406482\n",
      "[1947/11808 (16%)]\tLoss: 2.067650\tClass Loss: 0.752424\tDomain Loss: 1.315226\n",
      "[2097/11808 (18%)]\tLoss: 3.123834\tClass Loss: 1.825360\tDomain Loss: 1.298474\n",
      "[2247/11808 (19%)]\tLoss: 1.681856\tClass Loss: 0.004055\tDomain Loss: 1.677801\n",
      "[2397/11808 (20%)]\tLoss: 1.572916\tClass Loss: 0.168741\tDomain Loss: 1.404176\n",
      "[2547/11808 (22%)]\tLoss: 2.624091\tClass Loss: 1.255555\tDomain Loss: 1.368537\n",
      "[2697/11808 (23%)]\tLoss: 2.377051\tClass Loss: 0.908589\tDomain Loss: 1.468463\n",
      "[2847/11808 (24%)]\tLoss: 1.722839\tClass Loss: 0.194391\tDomain Loss: 1.528448\n",
      "[2997/11808 (25%)]\tLoss: 1.419255\tClass Loss: 0.111598\tDomain Loss: 1.307657\n",
      "[3147/11808 (27%)]\tLoss: 3.589375\tClass Loss: 2.111659\tDomain Loss: 1.477716\n",
      "[3297/11808 (28%)]\tLoss: 1.791438\tClass Loss: 0.437426\tDomain Loss: 1.354012\n",
      "[3447/11808 (29%)]\tLoss: 2.637083\tClass Loss: 1.199464\tDomain Loss: 1.437619\n",
      "[3597/11808 (30%)]\tLoss: 1.684610\tClass Loss: 0.379992\tDomain Loss: 1.304617\n",
      "[3747/11808 (32%)]\tLoss: 1.460586\tClass Loss: 0.100704\tDomain Loss: 1.359882\n",
      "[3897/11808 (33%)]\tLoss: 2.461810\tClass Loss: 1.138712\tDomain Loss: 1.323099\n",
      "[4047/11808 (34%)]\tLoss: 1.646168\tClass Loss: 0.308345\tDomain Loss: 1.337823\n",
      "[4197/11808 (36%)]\tLoss: 3.485304\tClass Loss: 1.940867\tDomain Loss: 1.544437\n",
      "[4347/11808 (37%)]\tLoss: 2.684674\tClass Loss: 1.433439\tDomain Loss: 1.251235\n",
      "[4497/11808 (38%)]\tLoss: 1.435661\tClass Loss: 0.016822\tDomain Loss: 1.418839\n",
      "[4647/11808 (39%)]\tLoss: 2.307204\tClass Loss: 0.925459\tDomain Loss: 1.381745\n",
      "[4797/11808 (41%)]\tLoss: 1.417017\tClass Loss: 0.012384\tDomain Loss: 1.404633\n",
      "[4947/11808 (42%)]\tLoss: 1.289908\tClass Loss: 0.041981\tDomain Loss: 1.247927\n",
      "[5097/11808 (43%)]\tLoss: 1.862589\tClass Loss: 0.572797\tDomain Loss: 1.289792\n",
      "[5247/11808 (44%)]\tLoss: 1.535411\tClass Loss: 0.125208\tDomain Loss: 1.410203\n",
      "[5397/11808 (46%)]\tLoss: 1.608861\tClass Loss: 0.293328\tDomain Loss: 1.315532\n",
      "[5547/11808 (47%)]\tLoss: 1.507141\tClass Loss: 0.176508\tDomain Loss: 1.330633\n",
      "[5697/11808 (48%)]\tLoss: 2.059561\tClass Loss: 0.680907\tDomain Loss: 1.378654\n",
      "[5847/11808 (50%)]\tLoss: 1.441406\tClass Loss: 0.033516\tDomain Loss: 1.407890\n",
      "[5997/11808 (51%)]\tLoss: 1.344344\tClass Loss: 0.034698\tDomain Loss: 1.309646\n",
      "[6147/11808 (52%)]\tLoss: 1.540683\tClass Loss: 0.203411\tDomain Loss: 1.337272\n",
      "[6297/11808 (53%)]\tLoss: 1.417836\tClass Loss: 0.041342\tDomain Loss: 1.376494\n",
      "[6447/11808 (55%)]\tLoss: 1.753702\tClass Loss: 0.431313\tDomain Loss: 1.322389\n",
      "[6597/11808 (56%)]\tLoss: 1.954595\tClass Loss: 0.492164\tDomain Loss: 1.462431\n",
      "[6747/11808 (57%)]\tLoss: 3.261227\tClass Loss: 1.733347\tDomain Loss: 1.527880\n",
      "[6897/11808 (58%)]\tLoss: 1.545436\tClass Loss: 0.225714\tDomain Loss: 1.319722\n",
      "[7047/11808 (60%)]\tLoss: 2.602440\tClass Loss: 1.251613\tDomain Loss: 1.350828\n",
      "[7197/11808 (61%)]\tLoss: 1.814844\tClass Loss: 0.506763\tDomain Loss: 1.308081\n",
      "[7347/11808 (62%)]\tLoss: 1.393378\tClass Loss: 0.023418\tDomain Loss: 1.369961\n",
      "[7497/11808 (63%)]\tLoss: 1.788263\tClass Loss: 0.545411\tDomain Loss: 1.242852\n",
      "[7647/11808 (65%)]\tLoss: 1.525732\tClass Loss: 0.274667\tDomain Loss: 1.251065\n",
      "[7797/11808 (66%)]\tLoss: 1.338174\tClass Loss: 0.010510\tDomain Loss: 1.327664\n",
      "[7947/11808 (67%)]\tLoss: 1.380625\tClass Loss: 0.026983\tDomain Loss: 1.353642\n",
      "[8097/11808 (69%)]\tLoss: 1.911551\tClass Loss: 0.524109\tDomain Loss: 1.387442\n",
      "[8247/11808 (70%)]\tLoss: 2.971250\tClass Loss: 1.528226\tDomain Loss: 1.443024\n",
      "[8397/11808 (71%)]\tLoss: 1.431617\tClass Loss: 0.079711\tDomain Loss: 1.351906\n",
      "[8547/11808 (72%)]\tLoss: 2.416239\tClass Loss: 1.018622\tDomain Loss: 1.397617\n",
      "[8697/11808 (74%)]\tLoss: 1.426214\tClass Loss: 0.022490\tDomain Loss: 1.403724\n",
      "[8847/11808 (75%)]\tLoss: 1.558338\tClass Loss: 0.268113\tDomain Loss: 1.290225\n",
      "[8997/11808 (76%)]\tLoss: 1.543773\tClass Loss: 0.233579\tDomain Loss: 1.310194\n",
      "[9147/11808 (77%)]\tLoss: 2.023153\tClass Loss: 0.714427\tDomain Loss: 1.308726\n",
      "[9297/11808 (79%)]\tLoss: 1.449255\tClass Loss: 0.031713\tDomain Loss: 1.417543\n",
      "[9447/11808 (80%)]\tLoss: 1.612153\tClass Loss: 0.106569\tDomain Loss: 1.505584\n",
      "[9597/11808 (81%)]\tLoss: 1.389181\tClass Loss: 0.051430\tDomain Loss: 1.337751\n",
      "[9747/11808 (83%)]\tLoss: 1.541279\tClass Loss: 0.067743\tDomain Loss: 1.473537\n",
      "[9897/11808 (84%)]\tLoss: 2.960270\tClass Loss: 1.535244\tDomain Loss: 1.425027\n",
      "[10047/11808 (85%)]\tLoss: 1.926550\tClass Loss: 0.533872\tDomain Loss: 1.392678\n",
      "[10197/11808 (86%)]\tLoss: 2.177848\tClass Loss: 0.876344\tDomain Loss: 1.301504\n",
      "[10347/11808 (88%)]\tLoss: 1.395195\tClass Loss: 0.022087\tDomain Loss: 1.373107\n",
      "[10497/11808 (89%)]\tLoss: 1.620274\tClass Loss: 0.128415\tDomain Loss: 1.491859\n",
      "[10647/11808 (90%)]\tLoss: 1.350150\tClass Loss: 0.020969\tDomain Loss: 1.329180\n",
      "[10797/11808 (91%)]\tLoss: 2.934340\tClass Loss: 1.487944\tDomain Loss: 1.446396\n",
      "[10947/11808 (93%)]\tLoss: 1.831077\tClass Loss: 0.446936\tDomain Loss: 1.384142\n",
      "[11097/11808 (94%)]\tLoss: 1.709966\tClass Loss: 0.254004\tDomain Loss: 1.455961\n",
      "[11247/11808 (95%)]\tLoss: 1.473792\tClass Loss: 0.242728\tDomain Loss: 1.231064\n",
      "[11397/11808 (97%)]\tLoss: 1.606209\tClass Loss: 0.271079\tDomain Loss: 1.335130\n",
      "[11547/11808 (98%)]\tLoss: 1.459845\tClass Loss: 0.087931\tDomain Loss: 1.371914\n",
      "[11697/11808 (99%)]\tLoss: 2.116837\tClass Loss: 0.650002\tDomain Loss: 1.466835\n",
      "\n",
      "Source Accuracy: 1832.0/2000 (91.6000%)\n",
      "Target Accuracy: 1096.0/2000 (54.8000%)\n",
      "\n",
      "Epoch: 3\n",
      "[147/11808 (1%)]\tLoss: 3.616461\tClass Loss: 2.231285\tDomain Loss: 1.385176\n",
      "[297/11808 (3%)]\tLoss: 3.759302\tClass Loss: 2.312393\tDomain Loss: 1.446908\n",
      "[447/11808 (4%)]\tLoss: 1.471274\tClass Loss: 0.168546\tDomain Loss: 1.302729\n",
      "[597/11808 (5%)]\tLoss: 1.320645\tClass Loss: 0.041248\tDomain Loss: 1.279397\n",
      "[747/11808 (6%)]\tLoss: 2.252963\tClass Loss: 0.754421\tDomain Loss: 1.498542\n",
      "[897/11808 (8%)]\tLoss: 2.266634\tClass Loss: 0.800436\tDomain Loss: 1.466198\n",
      "[1047/11808 (9%)]\tLoss: 1.707281\tClass Loss: 0.273947\tDomain Loss: 1.433334\n",
      "[1197/11808 (10%)]\tLoss: 1.308271\tClass Loss: 0.025286\tDomain Loss: 1.282985\n",
      "[1347/11808 (11%)]\tLoss: 1.481673\tClass Loss: 0.041844\tDomain Loss: 1.439828\n",
      "[1497/11808 (13%)]\tLoss: 1.532298\tClass Loss: 0.299142\tDomain Loss: 1.233156\n",
      "[1647/11808 (14%)]\tLoss: 2.957141\tClass Loss: 1.459858\tDomain Loss: 1.497283\n",
      "[1797/11808 (15%)]\tLoss: 1.330106\tClass Loss: 0.054701\tDomain Loss: 1.275405\n",
      "[1947/11808 (16%)]\tLoss: 2.869737\tClass Loss: 1.491637\tDomain Loss: 1.378100\n",
      "[2097/11808 (18%)]\tLoss: 2.225569\tClass Loss: 0.880953\tDomain Loss: 1.344616\n",
      "[2247/11808 (19%)]\tLoss: 1.435710\tClass Loss: 0.016252\tDomain Loss: 1.419458\n",
      "[2397/11808 (20%)]\tLoss: 1.337461\tClass Loss: 0.051379\tDomain Loss: 1.286082\n",
      "[2547/11808 (22%)]\tLoss: 1.363474\tClass Loss: 0.033844\tDomain Loss: 1.329630\n",
      "[2697/11808 (23%)]\tLoss: 1.967030\tClass Loss: 0.332698\tDomain Loss: 1.634332\n",
      "[2847/11808 (24%)]\tLoss: 1.450290\tClass Loss: 0.032642\tDomain Loss: 1.417648\n",
      "[2997/11808 (25%)]\tLoss: 1.990497\tClass Loss: 0.688602\tDomain Loss: 1.301895\n",
      "[3147/11808 (27%)]\tLoss: 1.424872\tClass Loss: 0.037275\tDomain Loss: 1.387598\n",
      "[3297/11808 (28%)]\tLoss: 1.537287\tClass Loss: 0.126687\tDomain Loss: 1.410601\n",
      "[3447/11808 (29%)]\tLoss: 1.943619\tClass Loss: 0.394895\tDomain Loss: 1.548724\n",
      "[3597/11808 (30%)]\tLoss: 1.419278\tClass Loss: 0.036460\tDomain Loss: 1.382818\n",
      "[3747/11808 (32%)]\tLoss: 1.378962\tClass Loss: 0.124593\tDomain Loss: 1.254369\n",
      "[3897/11808 (33%)]\tLoss: 1.407726\tClass Loss: 0.032976\tDomain Loss: 1.374750\n",
      "[4047/11808 (34%)]\tLoss: 2.310954\tClass Loss: 0.859163\tDomain Loss: 1.451791\n",
      "[4197/11808 (36%)]\tLoss: 1.407523\tClass Loss: 0.010320\tDomain Loss: 1.397202\n",
      "[4347/11808 (37%)]\tLoss: 2.246708\tClass Loss: 0.862698\tDomain Loss: 1.384011\n",
      "[4497/11808 (38%)]\tLoss: 2.085355\tClass Loss: 0.754099\tDomain Loss: 1.331256\n",
      "[4647/11808 (39%)]\tLoss: 1.525990\tClass Loss: 0.240785\tDomain Loss: 1.285205\n",
      "[4797/11808 (41%)]\tLoss: 1.467396\tClass Loss: 0.128226\tDomain Loss: 1.339169\n",
      "[4947/11808 (42%)]\tLoss: 1.621702\tClass Loss: 0.138557\tDomain Loss: 1.483145\n",
      "[5097/11808 (43%)]\tLoss: 2.630106\tClass Loss: 1.315374\tDomain Loss: 1.314732\n",
      "[5247/11808 (44%)]\tLoss: 1.707861\tClass Loss: 0.394400\tDomain Loss: 1.313461\n",
      "[5397/11808 (46%)]\tLoss: 2.299951\tClass Loss: 0.854984\tDomain Loss: 1.444967\n",
      "[5547/11808 (47%)]\tLoss: 2.701518\tClass Loss: 1.257607\tDomain Loss: 1.443911\n",
      "[5697/11808 (48%)]\tLoss: 1.714755\tClass Loss: 0.320193\tDomain Loss: 1.394562\n",
      "[5847/11808 (50%)]\tLoss: 1.326032\tClass Loss: 0.066039\tDomain Loss: 1.259994\n",
      "[5997/11808 (51%)]\tLoss: 1.618368\tClass Loss: 0.197377\tDomain Loss: 1.420990\n",
      "[6147/11808 (52%)]\tLoss: 1.945154\tClass Loss: 0.554069\tDomain Loss: 1.391085\n",
      "[6297/11808 (53%)]\tLoss: 1.528526\tClass Loss: 0.197117\tDomain Loss: 1.331409\n",
      "[6447/11808 (55%)]\tLoss: 1.911755\tClass Loss: 0.432808\tDomain Loss: 1.478946\n",
      "[6597/11808 (56%)]\tLoss: 1.409716\tClass Loss: 0.089672\tDomain Loss: 1.320045\n",
      "[6747/11808 (57%)]\tLoss: 3.228778\tClass Loss: 1.690484\tDomain Loss: 1.538295\n",
      "[6897/11808 (58%)]\tLoss: 1.577530\tClass Loss: 0.046630\tDomain Loss: 1.530900\n",
      "[7047/11808 (60%)]\tLoss: 1.499592\tClass Loss: 0.142915\tDomain Loss: 1.356677\n",
      "[7197/11808 (61%)]\tLoss: 3.077254\tClass Loss: 1.657577\tDomain Loss: 1.419677\n",
      "[7347/11808 (62%)]\tLoss: 1.699459\tClass Loss: 0.222448\tDomain Loss: 1.477011\n",
      "[7497/11808 (63%)]\tLoss: 1.603630\tClass Loss: 0.200692\tDomain Loss: 1.402938\n",
      "[7647/11808 (65%)]\tLoss: 1.583731\tClass Loss: 0.189980\tDomain Loss: 1.393751\n",
      "[7797/11808 (66%)]\tLoss: 1.394714\tClass Loss: 0.025133\tDomain Loss: 1.369581\n",
      "[7947/11808 (67%)]\tLoss: 1.614976\tClass Loss: 0.172663\tDomain Loss: 1.442313\n",
      "[8097/11808 (69%)]\tLoss: 1.502680\tClass Loss: 0.164806\tDomain Loss: 1.337873\n",
      "[8247/11808 (70%)]\tLoss: 1.570462\tClass Loss: 0.057577\tDomain Loss: 1.512885\n",
      "[8397/11808 (71%)]\tLoss: 1.730731\tClass Loss: 0.219320\tDomain Loss: 1.511410\n",
      "[8547/11808 (72%)]\tLoss: 1.449646\tClass Loss: 0.102415\tDomain Loss: 1.347231\n",
      "[8697/11808 (74%)]\tLoss: 1.250102\tClass Loss: 0.019067\tDomain Loss: 1.231035\n",
      "[8847/11808 (75%)]\tLoss: 1.649018\tClass Loss: 0.169302\tDomain Loss: 1.479716\n",
      "[8997/11808 (76%)]\tLoss: 1.338593\tClass Loss: 0.058159\tDomain Loss: 1.280435\n",
      "[9147/11808 (77%)]\tLoss: 1.450197\tClass Loss: 0.018794\tDomain Loss: 1.431404\n",
      "[9297/11808 (79%)]\tLoss: 1.572473\tClass Loss: 0.086994\tDomain Loss: 1.485479\n",
      "[9447/11808 (80%)]\tLoss: 1.384099\tClass Loss: 0.020195\tDomain Loss: 1.363904\n",
      "[9597/11808 (81%)]\tLoss: 3.041189\tClass Loss: 1.806270\tDomain Loss: 1.234920\n",
      "[9747/11808 (83%)]\tLoss: 1.553110\tClass Loss: 0.248819\tDomain Loss: 1.304291\n",
      "[9897/11808 (84%)]\tLoss: 1.633233\tClass Loss: 0.179531\tDomain Loss: 1.453702\n",
      "[10047/11808 (85%)]\tLoss: 1.484643\tClass Loss: 0.081452\tDomain Loss: 1.403190\n",
      "[10197/11808 (86%)]\tLoss: 1.949138\tClass Loss: 0.523288\tDomain Loss: 1.425850\n",
      "[10347/11808 (88%)]\tLoss: 1.523839\tClass Loss: 0.131157\tDomain Loss: 1.392682\n",
      "[10497/11808 (89%)]\tLoss: 1.534917\tClass Loss: 0.145310\tDomain Loss: 1.389606\n",
      "[10647/11808 (90%)]\tLoss: 1.439537\tClass Loss: 0.053717\tDomain Loss: 1.385820\n",
      "[10797/11808 (91%)]\tLoss: 1.641385\tClass Loss: 0.165923\tDomain Loss: 1.475461\n",
      "[10947/11808 (93%)]\tLoss: 1.246813\tClass Loss: 0.020381\tDomain Loss: 1.226432\n",
      "[11097/11808 (94%)]\tLoss: 1.509791\tClass Loss: 0.086445\tDomain Loss: 1.423345\n",
      "[11247/11808 (95%)]\tLoss: 1.551021\tClass Loss: 0.019582\tDomain Loss: 1.531439\n",
      "[11397/11808 (97%)]\tLoss: 2.032466\tClass Loss: 0.682259\tDomain Loss: 1.350207\n",
      "[11547/11808 (98%)]\tLoss: 1.408412\tClass Loss: 0.163456\tDomain Loss: 1.244956\n",
      "[11697/11808 (99%)]\tLoss: 1.431591\tClass Loss: 0.077417\tDomain Loss: 1.354174\n",
      "\n",
      "Source Accuracy: 1601.0/2000 (80.0500%)\n",
      "Target Accuracy: 1242.0/2000 (62.1000%)\n",
      "\n",
      "Epoch: 4\n",
      "[147/11808 (1%)]\tLoss: 2.478778\tClass Loss: 1.110755\tDomain Loss: 1.368022\n",
      "[297/11808 (3%)]\tLoss: 2.690969\tClass Loss: 1.160330\tDomain Loss: 1.530639\n",
      "[447/11808 (4%)]\tLoss: 1.422997\tClass Loss: 0.037958\tDomain Loss: 1.385039\n",
      "[597/11808 (5%)]\tLoss: 1.494957\tClass Loss: 0.041354\tDomain Loss: 1.453603\n",
      "[747/11808 (6%)]\tLoss: 1.557692\tClass Loss: 0.205518\tDomain Loss: 1.352173\n",
      "[897/11808 (8%)]\tLoss: 2.042635\tClass Loss: 0.693932\tDomain Loss: 1.348703\n",
      "[1047/11808 (9%)]\tLoss: 1.404807\tClass Loss: 0.046928\tDomain Loss: 1.357879\n",
      "[1197/11808 (10%)]\tLoss: 2.076780\tClass Loss: 0.787326\tDomain Loss: 1.289454\n",
      "[1347/11808 (11%)]\tLoss: 1.394615\tClass Loss: 0.147742\tDomain Loss: 1.246873\n",
      "[1497/11808 (13%)]\tLoss: 1.302119\tClass Loss: 0.031416\tDomain Loss: 1.270703\n",
      "[1647/11808 (14%)]\tLoss: 2.166672\tClass Loss: 0.927877\tDomain Loss: 1.238795\n",
      "[1797/11808 (15%)]\tLoss: 1.529281\tClass Loss: 0.038506\tDomain Loss: 1.490776\n",
      "[1947/11808 (16%)]\tLoss: 1.676825\tClass Loss: 0.325540\tDomain Loss: 1.351285\n",
      "[2097/11808 (18%)]\tLoss: 1.701301\tClass Loss: 0.330220\tDomain Loss: 1.371081\n",
      "[2247/11808 (19%)]\tLoss: 1.412850\tClass Loss: 0.106954\tDomain Loss: 1.305896\n",
      "[2397/11808 (20%)]\tLoss: 2.220450\tClass Loss: 0.754384\tDomain Loss: 1.466065\n",
      "[2547/11808 (22%)]\tLoss: 1.941465\tClass Loss: 0.536513\tDomain Loss: 1.404953\n",
      "[2697/11808 (23%)]\tLoss: 1.628623\tClass Loss: 0.085515\tDomain Loss: 1.543109\n",
      "[2847/11808 (24%)]\tLoss: 1.526948\tClass Loss: 0.135026\tDomain Loss: 1.391922\n",
      "[2997/11808 (25%)]\tLoss: 1.328535\tClass Loss: 0.053526\tDomain Loss: 1.275009\n",
      "[3147/11808 (27%)]\tLoss: 1.433044\tClass Loss: 0.054227\tDomain Loss: 1.378817\n",
      "[3297/11808 (28%)]\tLoss: 1.618879\tClass Loss: 0.103465\tDomain Loss: 1.515414\n",
      "[3447/11808 (29%)]\tLoss: 2.076654\tClass Loss: 0.768503\tDomain Loss: 1.308152\n",
      "[3597/11808 (30%)]\tLoss: 1.460915\tClass Loss: 0.086763\tDomain Loss: 1.374151\n",
      "[3747/11808 (32%)]\tLoss: 1.394156\tClass Loss: 0.145625\tDomain Loss: 1.248531\n",
      "[3897/11808 (33%)]\tLoss: 1.367699\tClass Loss: 0.022841\tDomain Loss: 1.344858\n",
      "[4047/11808 (34%)]\tLoss: 1.537628\tClass Loss: 0.083765\tDomain Loss: 1.453864\n",
      "[4197/11808 (36%)]\tLoss: 1.388882\tClass Loss: 0.051931\tDomain Loss: 1.336951\n",
      "[4347/11808 (37%)]\tLoss: 1.492093\tClass Loss: 0.173408\tDomain Loss: 1.318685\n",
      "[4497/11808 (38%)]\tLoss: 1.348696\tClass Loss: 0.008078\tDomain Loss: 1.340618\n",
      "[4647/11808 (39%)]\tLoss: 2.252340\tClass Loss: 0.839991\tDomain Loss: 1.412349\n",
      "[4797/11808 (41%)]\tLoss: 1.464429\tClass Loss: 0.041502\tDomain Loss: 1.422927\n",
      "[4947/11808 (42%)]\tLoss: 1.363275\tClass Loss: 0.028283\tDomain Loss: 1.334992\n",
      "[5097/11808 (43%)]\tLoss: 1.461748\tClass Loss: 0.062942\tDomain Loss: 1.398805\n",
      "[5247/11808 (44%)]\tLoss: 1.262290\tClass Loss: 0.025454\tDomain Loss: 1.236836\n",
      "[5397/11808 (46%)]\tLoss: 1.522944\tClass Loss: 0.069347\tDomain Loss: 1.453597\n",
      "[5547/11808 (47%)]\tLoss: 1.344648\tClass Loss: 0.048539\tDomain Loss: 1.296108\n",
      "[5697/11808 (48%)]\tLoss: 1.513416\tClass Loss: 0.176631\tDomain Loss: 1.336785\n",
      "[5847/11808 (50%)]\tLoss: 2.569056\tClass Loss: 1.100540\tDomain Loss: 1.468516\n",
      "[5997/11808 (51%)]\tLoss: 1.913965\tClass Loss: 0.612786\tDomain Loss: 1.301179\n",
      "[6147/11808 (52%)]\tLoss: 2.163739\tClass Loss: 0.811757\tDomain Loss: 1.351982\n",
      "[6297/11808 (53%)]\tLoss: 2.382554\tClass Loss: 0.932071\tDomain Loss: 1.450483\n",
      "[6447/11808 (55%)]\tLoss: 1.368378\tClass Loss: 0.033183\tDomain Loss: 1.335195\n",
      "[6597/11808 (56%)]\tLoss: 1.695696\tClass Loss: 0.377518\tDomain Loss: 1.318177\n",
      "[6747/11808 (57%)]\tLoss: 1.477755\tClass Loss: 0.023357\tDomain Loss: 1.454398\n",
      "[6897/11808 (58%)]\tLoss: 1.595794\tClass Loss: 0.065875\tDomain Loss: 1.529919\n",
      "[7047/11808 (60%)]\tLoss: 1.591622\tClass Loss: 0.236787\tDomain Loss: 1.354835\n",
      "[7197/11808 (61%)]\tLoss: 2.750088\tClass Loss: 1.316144\tDomain Loss: 1.433944\n",
      "[7347/11808 (62%)]\tLoss: 1.698725\tClass Loss: 0.289831\tDomain Loss: 1.408894\n",
      "[7497/11808 (63%)]\tLoss: 2.144367\tClass Loss: 0.864328\tDomain Loss: 1.280039\n",
      "[7647/11808 (65%)]\tLoss: 3.133062\tClass Loss: 1.641778\tDomain Loss: 1.491284\n",
      "[7797/11808 (66%)]\tLoss: 1.660315\tClass Loss: 0.241513\tDomain Loss: 1.418802\n",
      "[7947/11808 (67%)]\tLoss: 1.304222\tClass Loss: 0.015893\tDomain Loss: 1.288329\n",
      "[8097/11808 (69%)]\tLoss: 2.132334\tClass Loss: 0.688308\tDomain Loss: 1.444026\n",
      "[8247/11808 (70%)]\tLoss: 1.909495\tClass Loss: 0.618055\tDomain Loss: 1.291440\n",
      "[8397/11808 (71%)]\tLoss: 2.363385\tClass Loss: 1.082065\tDomain Loss: 1.281320\n",
      "[8547/11808 (72%)]\tLoss: 1.367835\tClass Loss: 0.024194\tDomain Loss: 1.343641\n",
      "[8697/11808 (74%)]\tLoss: 1.473054\tClass Loss: 0.081225\tDomain Loss: 1.391829\n",
      "[8847/11808 (75%)]\tLoss: 1.859057\tClass Loss: 0.427414\tDomain Loss: 1.431644\n",
      "[8997/11808 (76%)]\tLoss: 2.010929\tClass Loss: 0.671074\tDomain Loss: 1.339856\n",
      "[9147/11808 (77%)]\tLoss: 1.411034\tClass Loss: 0.126135\tDomain Loss: 1.284898\n",
      "[9297/11808 (79%)]\tLoss: 1.281577\tClass Loss: 0.068441\tDomain Loss: 1.213136\n",
      "[9447/11808 (80%)]\tLoss: 1.621235\tClass Loss: 0.267032\tDomain Loss: 1.354203\n",
      "[9597/11808 (81%)]\tLoss: 2.512243\tClass Loss: 1.079444\tDomain Loss: 1.432799\n",
      "[9747/11808 (83%)]\tLoss: 1.919115\tClass Loss: 0.538864\tDomain Loss: 1.380251\n",
      "[9897/11808 (84%)]\tLoss: 2.132836\tClass Loss: 0.827137\tDomain Loss: 1.305699\n",
      "[10047/11808 (85%)]\tLoss: 1.456174\tClass Loss: 0.027506\tDomain Loss: 1.428668\n",
      "[10197/11808 (86%)]\tLoss: 2.211637\tClass Loss: 0.741600\tDomain Loss: 1.470036\n",
      "[10347/11808 (88%)]\tLoss: 1.732897\tClass Loss: 0.331097\tDomain Loss: 1.401800\n",
      "[10497/11808 (89%)]\tLoss: 1.750550\tClass Loss: 0.209246\tDomain Loss: 1.541304\n",
      "[10647/11808 (90%)]\tLoss: 1.760394\tClass Loss: 0.403079\tDomain Loss: 1.357315\n",
      "[10797/11808 (91%)]\tLoss: 1.508098\tClass Loss: 0.084841\tDomain Loss: 1.423257\n",
      "[10947/11808 (93%)]\tLoss: 2.854296\tClass Loss: 1.430807\tDomain Loss: 1.423489\n",
      "[11097/11808 (94%)]\tLoss: 1.490766\tClass Loss: 0.075617\tDomain Loss: 1.415149\n",
      "[11247/11808 (95%)]\tLoss: 2.441500\tClass Loss: 1.112134\tDomain Loss: 1.329367\n",
      "[11397/11808 (97%)]\tLoss: 1.456116\tClass Loss: 0.038145\tDomain Loss: 1.417971\n",
      "[11547/11808 (98%)]\tLoss: 1.472588\tClass Loss: 0.015729\tDomain Loss: 1.456859\n",
      "[11697/11808 (99%)]\tLoss: 1.905529\tClass Loss: 0.601879\tDomain Loss: 1.303650\n",
      "\n",
      "Source Accuracy: 1857.0/2000 (92.8500%)\n",
      "Target Accuracy: 1055.0/2000 (52.7500%)\n",
      "\n",
      "Epoch: 5\n",
      "[147/11808 (1%)]\tLoss: 2.845275\tClass Loss: 1.498348\tDomain Loss: 1.346928\n",
      "[297/11808 (3%)]\tLoss: 1.299262\tClass Loss: 0.035505\tDomain Loss: 1.263757\n",
      "[447/11808 (4%)]\tLoss: 1.606340\tClass Loss: 0.151382\tDomain Loss: 1.454958\n",
      "[597/11808 (5%)]\tLoss: 1.809120\tClass Loss: 0.364346\tDomain Loss: 1.444774\n",
      "[747/11808 (6%)]\tLoss: 1.446154\tClass Loss: 0.073008\tDomain Loss: 1.373146\n",
      "[897/11808 (8%)]\tLoss: 1.547605\tClass Loss: 0.228480\tDomain Loss: 1.319125\n",
      "[1047/11808 (9%)]\tLoss: 1.427491\tClass Loss: 0.048273\tDomain Loss: 1.379218\n",
      "[1197/11808 (10%)]\tLoss: 1.882115\tClass Loss: 0.485984\tDomain Loss: 1.396130\n",
      "[1347/11808 (11%)]\tLoss: 1.386080\tClass Loss: 0.135649\tDomain Loss: 1.250431\n",
      "[1497/11808 (13%)]\tLoss: 1.627807\tClass Loss: 0.210990\tDomain Loss: 1.416817\n",
      "[1647/11808 (14%)]\tLoss: 1.587051\tClass Loss: 0.130558\tDomain Loss: 1.456492\n",
      "[1797/11808 (15%)]\tLoss: 3.551351\tClass Loss: 2.168423\tDomain Loss: 1.382928\n",
      "[1947/11808 (16%)]\tLoss: 1.435474\tClass Loss: 0.031365\tDomain Loss: 1.404109\n",
      "[2097/11808 (18%)]\tLoss: 1.371650\tClass Loss: 0.006863\tDomain Loss: 1.364787\n",
      "[2247/11808 (19%)]\tLoss: 2.343322\tClass Loss: 1.068991\tDomain Loss: 1.274330\n",
      "[2397/11808 (20%)]\tLoss: 1.363079\tClass Loss: 0.032175\tDomain Loss: 1.330904\n",
      "[2547/11808 (22%)]\tLoss: 1.391267\tClass Loss: 0.045580\tDomain Loss: 1.345687\n",
      "[2697/11808 (23%)]\tLoss: 1.473424\tClass Loss: 0.210113\tDomain Loss: 1.263312\n",
      "[2847/11808 (24%)]\tLoss: 1.544872\tClass Loss: 0.114085\tDomain Loss: 1.430786\n",
      "[2997/11808 (25%)]\tLoss: 1.355013\tClass Loss: 0.053439\tDomain Loss: 1.301575\n",
      "[3147/11808 (27%)]\tLoss: 2.202612\tClass Loss: 0.784801\tDomain Loss: 1.417812\n",
      "[3297/11808 (28%)]\tLoss: 1.497752\tClass Loss: 0.149268\tDomain Loss: 1.348484\n",
      "[3447/11808 (29%)]\tLoss: 1.825888\tClass Loss: 0.435591\tDomain Loss: 1.390297\n",
      "[3597/11808 (30%)]\tLoss: 1.436335\tClass Loss: 0.150476\tDomain Loss: 1.285860\n",
      "[3747/11808 (32%)]\tLoss: 1.458128\tClass Loss: 0.072860\tDomain Loss: 1.385267\n",
      "[3897/11808 (33%)]\tLoss: 1.615285\tClass Loss: 0.393502\tDomain Loss: 1.221782\n",
      "[4047/11808 (34%)]\tLoss: 2.816345\tClass Loss: 1.410213\tDomain Loss: 1.406131\n",
      "[4197/11808 (36%)]\tLoss: 2.130582\tClass Loss: 0.708419\tDomain Loss: 1.422162\n",
      "[4347/11808 (37%)]\tLoss: 1.328469\tClass Loss: 0.062863\tDomain Loss: 1.265606\n",
      "[4497/11808 (38%)]\tLoss: 1.448150\tClass Loss: 0.019810\tDomain Loss: 1.428340\n",
      "[4647/11808 (39%)]\tLoss: 2.168768\tClass Loss: 0.761244\tDomain Loss: 1.407525\n",
      "[4797/11808 (41%)]\tLoss: 1.344899\tClass Loss: 0.044132\tDomain Loss: 1.300767\n",
      "[4947/11808 (42%)]\tLoss: 1.585654\tClass Loss: 0.027199\tDomain Loss: 1.558455\n",
      "[5097/11808 (43%)]\tLoss: 1.318019\tClass Loss: 0.029527\tDomain Loss: 1.288492\n",
      "[5247/11808 (44%)]\tLoss: 1.609385\tClass Loss: 0.177648\tDomain Loss: 1.431737\n",
      "[5397/11808 (46%)]\tLoss: 1.800657\tClass Loss: 0.508411\tDomain Loss: 1.292246\n",
      "[5547/11808 (47%)]\tLoss: 1.564456\tClass Loss: 0.160422\tDomain Loss: 1.404033\n",
      "[5697/11808 (48%)]\tLoss: 1.676762\tClass Loss: 0.238976\tDomain Loss: 1.437785\n",
      "[5847/11808 (50%)]\tLoss: 1.458831\tClass Loss: 0.021753\tDomain Loss: 1.437079\n",
      "[5997/11808 (51%)]\tLoss: 1.876453\tClass Loss: 0.395315\tDomain Loss: 1.481138\n",
      "[6147/11808 (52%)]\tLoss: 2.105257\tClass Loss: 0.720712\tDomain Loss: 1.384545\n",
      "[6297/11808 (53%)]\tLoss: 1.484428\tClass Loss: 0.098016\tDomain Loss: 1.386412\n",
      "[6447/11808 (55%)]\tLoss: 1.322573\tClass Loss: 0.020037\tDomain Loss: 1.302537\n",
      "[6597/11808 (56%)]\tLoss: 1.407248\tClass Loss: 0.014798\tDomain Loss: 1.392450\n",
      "[6747/11808 (57%)]\tLoss: 2.512015\tClass Loss: 1.176476\tDomain Loss: 1.335539\n",
      "[6897/11808 (58%)]\tLoss: 1.423659\tClass Loss: 0.017662\tDomain Loss: 1.405997\n",
      "[7047/11808 (60%)]\tLoss: 1.679620\tClass Loss: 0.180401\tDomain Loss: 1.499219\n",
      "[7197/11808 (61%)]\tLoss: 1.444118\tClass Loss: 0.069431\tDomain Loss: 1.374687\n",
      "[7347/11808 (62%)]\tLoss: 1.694780\tClass Loss: 0.276514\tDomain Loss: 1.418266\n",
      "[7497/11808 (63%)]\tLoss: 2.458894\tClass Loss: 1.108101\tDomain Loss: 1.350793\n",
      "[7647/11808 (65%)]\tLoss: 1.459185\tClass Loss: 0.161593\tDomain Loss: 1.297592\n",
      "[7797/11808 (66%)]\tLoss: 1.390324\tClass Loss: 0.014423\tDomain Loss: 1.375900\n",
      "[7947/11808 (67%)]\tLoss: 1.443346\tClass Loss: 0.075526\tDomain Loss: 1.367820\n",
      "[8097/11808 (69%)]\tLoss: 1.547539\tClass Loss: 0.226796\tDomain Loss: 1.320743\n",
      "[8247/11808 (70%)]\tLoss: 3.254410\tClass Loss: 1.732562\tDomain Loss: 1.521848\n",
      "[8397/11808 (71%)]\tLoss: 1.488802\tClass Loss: 0.197200\tDomain Loss: 1.291602\n",
      "[8547/11808 (72%)]\tLoss: 1.540032\tClass Loss: 0.043272\tDomain Loss: 1.496760\n",
      "[8697/11808 (74%)]\tLoss: 1.392867\tClass Loss: 0.017672\tDomain Loss: 1.375195\n",
      "[8847/11808 (75%)]\tLoss: 1.862223\tClass Loss: 0.386669\tDomain Loss: 1.475554\n",
      "[8997/11808 (76%)]\tLoss: 1.950951\tClass Loss: 0.547743\tDomain Loss: 1.403208\n",
      "[9147/11808 (77%)]\tLoss: 2.047305\tClass Loss: 0.648869\tDomain Loss: 1.398436\n",
      "[9297/11808 (79%)]\tLoss: 1.651911\tClass Loss: 0.296072\tDomain Loss: 1.355840\n",
      "[9447/11808 (80%)]\tLoss: 1.654682\tClass Loss: 0.194515\tDomain Loss: 1.460167\n",
      "[9597/11808 (81%)]\tLoss: 2.042346\tClass Loss: 0.529394\tDomain Loss: 1.512952\n",
      "[9747/11808 (83%)]\tLoss: 1.293183\tClass Loss: 0.031750\tDomain Loss: 1.261433\n",
      "[9897/11808 (84%)]\tLoss: 1.376303\tClass Loss: 0.055628\tDomain Loss: 1.320675\n",
      "[10047/11808 (85%)]\tLoss: 1.776039\tClass Loss: 0.424708\tDomain Loss: 1.351331\n",
      "[10197/11808 (86%)]\tLoss: 1.897584\tClass Loss: 0.580747\tDomain Loss: 1.316837\n",
      "[10347/11808 (88%)]\tLoss: 1.629963\tClass Loss: 0.221382\tDomain Loss: 1.408581\n",
      "[10497/11808 (89%)]\tLoss: 1.664003\tClass Loss: 0.242988\tDomain Loss: 1.421015\n",
      "[10647/11808 (90%)]\tLoss: 1.616816\tClass Loss: 0.201930\tDomain Loss: 1.414886\n",
      "[10797/11808 (91%)]\tLoss: 1.897216\tClass Loss: 0.412029\tDomain Loss: 1.485188\n",
      "[10947/11808 (93%)]\tLoss: 2.367961\tClass Loss: 0.844579\tDomain Loss: 1.523382\n",
      "[11097/11808 (94%)]\tLoss: 3.525124\tClass Loss: 2.005286\tDomain Loss: 1.519839\n",
      "[11247/11808 (95%)]\tLoss: 1.337296\tClass Loss: 0.130927\tDomain Loss: 1.206369\n",
      "[11397/11808 (97%)]\tLoss: 1.496109\tClass Loss: 0.019817\tDomain Loss: 1.476292\n",
      "[11547/11808 (98%)]\tLoss: 1.374376\tClass Loss: 0.044664\tDomain Loss: 1.329712\n",
      "[11697/11808 (99%)]\tLoss: 1.612170\tClass Loss: 0.200898\tDomain Loss: 1.411272\n",
      "\n",
      "Source Accuracy: 1879.0/2000 (93.9500%)\n",
      "Target Accuracy: 1156.0/2000 (57.8000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#intializing classes/variables necessary for training\n",
    "feature_extractor = SVHN_Extractor()\n",
    "class_classifier = SVHN_Class_classifier()\n",
    "domain_classifier = SVHN_Domain_classifier()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for model in [feature_extractor, class_classifier, domain_classifier]:\n",
    "        model.cuda()\n",
    "\n",
    "curr_optimizer = torch.optim.SGD([{'params': feature_extractor.parameters()},\n",
    "                        {'params': class_classifier.parameters()},\n",
    "                        {'params': domain_classifier.parameters()}], lr= .01, momentum= 0.9)\n",
    "\n",
    "#running the code to train the model\n",
    "for epoch in range(max_epochs):\n",
    "        print('Epoch: {}'.format(epoch+1))\n",
    "        train(\n",
    "            training_mode = 'dann',\n",
    "            feature_extractor = feature_extractor,\n",
    "            class_classifier = class_classifier,\n",
    "            domain_classifier = domain_classifier,\n",
    "            class_criterion = nn.NLLLoss(),\n",
    "            domain_criterion = nn.NLLLoss(),\n",
    "            source_dataloader = dl_source_train,\n",
    "            target_dataloader = dl_target_train,\n",
    "            optimizer = curr_optimizer,\n",
    "            epoch = epoch)\n",
    "        test(feature_extractor, class_classifier, domain_classifier, dl_source_test, dl_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "_SK9Ao11u_E2",
    "outputId": "b1c1c357-c104-4994-ac53-6c4dbd80302f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(range(len(src_acc)), src_acc, label=\"Source\")\n",
    "ax.plot(range(len(tgt_acc)), tgt_acc, label=\"Target\")\n",
    "plt.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBAZ5kCwbNTo",
    "outputId": "668fc26e-ea43-4991-bf72-f0746b851105"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.95"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(src_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sV-d-ZTxvBf5",
    "outputId": "86617721-5d0e-4ab8-bdf4-8130464f5675"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.25"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tgt_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS550 DANN Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
